{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fRdbEJCUyJLj",
   "metadata": {
    "id": "fRdbEJCUyJLj"
   },
   "source": [
    "# Hands-on: Parallel Computing Applied to Industry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n12FbzH_yJLl",
   "metadata": {
    "id": "n12FbzH_yJLl"
   },
   "source": [
    "Welcome to _Hands-on_. In this short course you will learn several techniques for scaling computation on industrial applications, with an emphasis on [OPENMP, OPENACC, CUDA] which allows for elegant parallelization applications codes and has been proven to scale very well on supercomputational systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FUm5HQBwyJLm",
   "metadata": {
    "id": "FUm5HQBwyJLm"
   },
   "source": [
    "## The Coding Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m13auaYIyJLm",
   "metadata": {
    "id": "m13auaYIyJLm"
   },
   "source": [
    "For your work today, you have access to several computational resources in the cloud. Run the following cell to see the features available to you today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3ff15b-3853-49eb-91ca-220ff5d735b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yqipQLSmyJLn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1666529339545,
     "user": {
      "displayName": "Murilo Boratto",
      "userId": "13998345321799991370"
     },
     "user_tz": 180
    },
    "id": "yqipQLSmyJLn",
    "outputId": "24b09446-c372-475f-e4ce-bb2e292517e4"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi topo -m "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ws-Hn9CgyJLp",
   "metadata": {
    "id": "Ws-Hn9CgyJLp"
   },
   "source": [
    "While your work today will be on a single node, all the techniques you learn today, can be used to run your applications across clusters of multi-GPU nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89507cf3-343c-496e-b0ce-1bdfe6ce0435",
   "metadata": {},
   "source": [
    "## Environment Modules on OGBON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae011059-a2b1-48be-b313-4d4b3cf43769",
   "metadata": {},
   "source": [
    "These modules must be initialized before running the jupyter-notebook:\n",
    "```cpp\n",
    "Currently Loaded Modulefiles:\n",
    "    1) anaconda3/2022.05 \n",
    "    2) cuda/11.6         \n",
    "    3) ucx/1.12.0-cuda-11.6-ofed-5.4\n",
    "    4) gcc/11.1.0  \n",
    "    5) openmpi/4.1.1-cuda-11.6-ofed-5.4\n",
    "    6) intel/parallel-studio-xe/2020.2    \n",
    "    7) nvhpc/22.11\n",
    "    8) llvm/11.0.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Jq8Zc_8byJLp",
   "metadata": {
    "id": "Jq8Zc_8byJLp"
   },
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vn9m6S-jyJLq",
   "metadata": {
    "id": "vn9m6S-jyJLq"
   },
   "source": [
    "During the workshop today you will work through each of the following notebooks with your instructor:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GN2WM2cXyJLq",
   "metadata": {
    "id": "GN2WM2cXyJLq"
   },
   "source": [
    "- [Accelerate a Thermal Conductivity Application](2-heat.ipynb): You will begin by familiarizing yourself with a single GPU implementation of the Accelerate a Thermal Conductivity Application, which we will use to introduce  multi-resources programming paradigms.\n",
    "- [Seismic Modelling - 1D Wave Equation](3-wave.ipynb): You apply your day's learnings by refactoring a single GPU 1D wave equation solver to run on supercomputing environment.\n",
    "- [Final Exercise](4-finalExercise.ipynb): In this exercise you apply your concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bzhJyfWIyJLr",
   "metadata": {
    "id": "bzhJyfWIyJLr"
   },
   "source": [
    "## `Matrix Multiple Benchmarks`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XY0PHc4eyJLr",
   "metadata": {
    "id": "XY0PHc4eyJLr"
   },
   "source": [
    "### ⊗ Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DcJxHVSzyJLr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1666529352426,
     "user": {
      "displayName": "Murilo Boratto",
      "userId": "13998345321799991370"
     },
     "user_tz": 180
    },
    "id": "DcJxHVSzyJLr",
    "outputId": "745549f1-3ecd-4f11-bf6c-4271e6e598b6"
   },
   "outputs": [],
   "source": [
    "%%writefile mm.c\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "void fill_matrix(double *A, int n){\n",
    "\n",
    "  for(int i = 0; i < n; i++)\n",
    "    for(int j = 0; j < n; j++)\n",
    "      A[i*n+j] = rand()%(10-1)*1;\n",
    "\n",
    "}\n",
    "\n",
    "void print_matrix(double *A, int n){\n",
    "\n",
    "  int i,j;\n",
    "\n",
    "  for(int i = 0; i < n; i++){\n",
    "    for(int j = 0; j < n; j++)\n",
    "      printf(\"%1.2f\\t\", A[i*n+j]);\n",
    "    printf(\"\\n\");\n",
    "  }\n",
    "\n",
    "  printf(\"\\n\");\n",
    "\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv){\n",
    "\n",
    " int n = atoi(argv[1]);\n",
    " int i, j, k;\n",
    "\n",
    " double  *A = (double *) malloc (sizeof(double) * n * n);\n",
    " double  *B = (double *) malloc (sizeof(double) * n * n);\n",
    " double  *C = (double *) malloc (sizeof(double) * n * n);\n",
    "\n",
    " fill_matrix(A,n);\n",
    " fill_matrix(B,n);\n",
    "\n",
    " //Measuring time\n",
    "  struct timeval begin, end;\n",
    "  gettimeofday(&begin, 0);\n",
    "\n",
    " for(i = 0; i < n; i++)\n",
    "  for(j = 0; j < n; j++)\n",
    "    for(k = 0; k < n; k++)\n",
    "      C[i*n+j]+=A[i*n+k]*B[k*n+j];\n",
    "\n",
    " gettimeofday(&end, 0);\n",
    " double elapsed = (end.tv_sec - begin.tv_sec) + (end.tv_usec - begin.tv_usec)*1e-6;\n",
    "\n",
    " printf(\"%d x %d  %.3f seconds\\n\", n, n, elapsed);\n",
    "\n",
    " //print_matrix(A,n);\n",
    " //print_matrix(B,n);\n",
    " //print_matrix(C,n);\n",
    "\n",
    " return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "G1nTnPVxyJLt",
   "metadata": {
    "id": "G1nTnPVxyJLt"
   },
   "outputs": [],
   "source": [
    "!gcc mm.c -o mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OV8zXBHkyJLt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1666529362942,
     "user": {
      "displayName": "Murilo Boratto",
      "userId": "13998345321799991370"
     },
     "user_tz": 180
    },
    "id": "OV8zXBHkyJLt",
    "outputId": "ee343f9f-65cc-4563-ce60-5bbbd7fa389b"
   },
   "outputs": [],
   "source": [
    "!./mm 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8XMxBMeLyJL1",
   "metadata": {
    "id": "8XMxBMeLyJL1"
   },
   "source": [
    "### ⊗ OpenMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C_m8PlpyyJL1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 246,
     "status": "ok",
     "timestamp": 1666529441953,
     "user": {
      "displayName": "Murilo Boratto",
      "userId": "13998345321799991370"
     },
     "user_tz": 180
    },
    "id": "C_m8PlpyyJL1",
    "outputId": "4cea6da7-f313-4504-85ef-04dfb23cca36"
   },
   "outputs": [],
   "source": [
    "%%writefile mm-omp.c\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <omp.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "void fill_matrix(double *A, int n)\n",
    "{\n",
    "  for(int i = 0; i < n; i++)\n",
    "    for(int j = 0; j < n; j++)\n",
    "      A[i*n+j] = rand()%(10-1)*1;\n",
    "}\n",
    "\n",
    "void print_matrix(double *A, int n)\n",
    "{\n",
    "  for(int i = 0; i < n; i++){\n",
    "    for(int j = 0; j < n; j++)\n",
    "      printf(\"%1.2f\\t\", A[i*n+j]);\n",
    "   printf(\"\\n\");\n",
    "  }\n",
    "\n",
    "  printf(\"\\n\");\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv)\n",
    "{\n",
    "  int n = atoi(argv[1]);  \n",
    "  int i, j, k;\n",
    "  struct timeval begin, end;\n",
    "  \n",
    "  double  *A = (double *) malloc(sizeof(double) * n * n);\n",
    "  double  *B = (double *) malloc(sizeof(double) * n * n);\n",
    "  double  *C = (double *) malloc(sizeof(double) * n * n);\n",
    "\n",
    "  fill_matrix(A,n);\n",
    "  fill_matrix(B,n);\n",
    "\n",
    "  gettimeofday(&begin, 0);\n",
    "     \n",
    "  #pragma omp parallel for private(i,j,k)\n",
    "   for(i = 0; i < n; i++) \n",
    "    for(j = 0; j < n; j++)\n",
    "      for(k = 0; k < n; k++) \n",
    "        C[i*n+j] += A[i*n+k] * B[k*n+j];\n",
    "    \n",
    "   gettimeofday(&end, 0);\n",
    "  \n",
    "   long seconds = end.tv_sec - begin.tv_sec;\n",
    "   long microseconds = end.tv_usec - begin.tv_usec;\n",
    "   double elapsed = seconds + microseconds*1e-6;\n",
    "    \n",
    "   printf(\"%d x %d  %.2f seconds\\n\", n, n, elapsed);    \n",
    "    \n",
    "   //print_matrix(A,n);\n",
    "   //print_matrix(B,n);\n",
    "   //print_matrix(C,n);\n",
    "\n",
    "   return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2JgO0tpbyJL2",
   "metadata": {
    "id": "2JgO0tpbyJL2"
   },
   "outputs": [],
   "source": [
    "!gcc mm-omp.c -o mm-omp -fopenmp -O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nFLmUncjyJL2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 646,
     "status": "ok",
     "timestamp": 1666529486235,
     "user": {
      "displayName": "Murilo Boratto",
      "userId": "13998345321799991370"
     },
     "user_tz": 180
    },
    "id": "nFLmUncjyJL2",
    "outputId": "75aaae82-fedf-4579-9b6e-6e2a968cfdbf"
   },
   "outputs": [],
   "source": [
    "!OMP_NUM_THREADS=1 ./mm-omp 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pTgr8x0GyJL2",
   "metadata": {
    "id": "pTgr8x0GyJL2"
   },
   "source": [
    "### ⊗ CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "Ypu7QTttyJL3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1666556061590,
     "user": {
      "displayName": "Murilo Boratto",
      "userId": "13998345321799991370"
     },
     "user_tz": 180
    },
    "id": "Ypu7QTttyJL3",
    "outputId": "133eeb91-57b0-4892-eb59-9e4a6cac05db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mm-CUDA.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile mm-CUDA.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "__global__ void kernel(double *A, double *B, double *C, int n) \n",
    "{  \n",
    "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  int j = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "\n",
    "  if(i < n && j < n)\n",
    "    for( int k = 0; k < n; k++) \n",
    "       C[i*n+j] += A[i*n+k] * B[k*n+j];\n",
    "\n",
    "}\n",
    " \n",
    "void mult_matrix_cpu(double *A, double *B, double *C, int n) \n",
    "{\n",
    "   for(int i = 0; i < n; i++) \n",
    "      for(int j = 0; j < n; j++)\n",
    "         for(int k = 0; k < n; k++) \n",
    "            C[i*n+j]+=A[i*n+k]*B[k*n+j];\n",
    "        \n",
    "}\n",
    "\n",
    "void fill_matrix(double *A, int n)\n",
    "{ \n",
    "   for(int i=0; i < n; i++)\n",
    "     for(int j=0; j < n; j++)\n",
    "       A[i*n+j] = rand()%(10-1)*1;\n",
    "   \n",
    "}\n",
    "\n",
    "void print_matrix(double *A, int n)\n",
    "{\n",
    "  for(int i = 0; i < n; i++){\n",
    "    for(int j = 0; j < n; j++)\n",
    "      printf(\"%1.2f\\t\", A[i*n+j]);\n",
    "    printf(\"\\n\");\n",
    "  }\n",
    "\n",
    "  printf(\"\\n\");\n",
    "\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv)\n",
    "{\n",
    "    int n = atoi(argv[1]);\n",
    "    int sizeblock = atoi(argv[2]);\n",
    "    struct timeval begin, end;\n",
    "\n",
    "    /*Host*/\n",
    "    double *A_host=(double *) malloc (n * n * sizeof(double));\n",
    "    double *B_host=(double *) malloc (n * n * sizeof(double));\n",
    "    double *C_host=(double *) malloc (n * n * sizeof(double));\n",
    "        \n",
    "    fill_matrix(A_host,n);\n",
    "    fill_matrix(B_host,n);\n",
    "      \n",
    "    //print_matrix(A_host,n);\n",
    "    //print_matrix(B_host,n);\n",
    "\n",
    "    gettimeofday(&begin, 0);\n",
    "    \n",
    "    /*Device*/\n",
    "    double *A_device;\n",
    "    double *B_device;\n",
    "    double *C_device;\n",
    "\n",
    "    cudaMalloc((void**)&A_device, n * n * sizeof(double) ); \n",
    "    cudaMalloc((void**)&B_device, n * n * sizeof(double) ); \n",
    "    cudaMalloc((void**)&C_device, n * n * sizeof(double) ); \n",
    "\n",
    "    cudaMemcpy(A_device, A_host, n * n * sizeof(double), cudaMemcpyHostToDevice ); \n",
    "    cudaMemcpy(B_device, B_host, n * n * sizeof(double), cudaMemcpyHostToDevice ); \n",
    "\n",
    "    /*Computational GRID: (Grid: 2D Block: 2D)*/\n",
    "    dim3 NUMBER_OF_BLOCKS ( (int) ceil( (float) n / sizeblock), (int) ceil( (float)n / sizeblock) );\n",
    "    dim3 NUMBER_OF_THREADS( sizeblock, sizeblock);  \n",
    "\n",
    "          kernel<<< NUMBER_OF_BLOCKS, NUMBER_OF_THREADS >>>(A_device, B_device, C_device, n);      \n",
    "\n",
    "    cudaMemcpy(C_host, C_device, n * n * sizeof(double), cudaMemcpyDeviceToHost ); \n",
    "\n",
    "    //print_matrix(C_host, n );\n",
    "\n",
    "    gettimeofday(&end, 0);\n",
    "    \n",
    "    long seconds = end.tv_sec - begin.tv_sec;\n",
    "    long microseconds = end.tv_usec - begin.tv_usec;\n",
    "    double elapsed = seconds + microseconds*1e-6;\n",
    "    \n",
    "    printf(\"%d x %d  %.3f seconds\\n\", n, n, elapsed);  \n",
    "    \n",
    "    cudaFree(A_device );\n",
    "    cudaFree(B_device );\n",
    "    cudaFree(C_device );\n",
    "  \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "G9eK7uvvyJL3",
   "metadata": {
    "id": "G9eK7uvvyJL3"
   },
   "outputs": [],
   "source": [
    "!nvcc mm-CUDA.cu -o mm-CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9lQDO3hpyJL3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 692,
     "status": "ok",
     "timestamp": 1666556070589,
     "user": {
      "displayName": "Murilo Boratto",
      "userId": "13998345321799991370"
     },
     "user_tz": 180
    },
    "id": "9lQDO3hpyJL3",
    "outputId": "d7a17746-13d9-405d-d122-c8e626b6a396"
   },
   "outputs": [],
   "source": [
    "!./mm-CUDA 1000 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eTtb7CD_yJL4",
   "metadata": {
    "id": "eTtb7CD_yJL4"
   },
   "source": [
    "### ⊗ OpenACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ReO-ytcuyJL4",
   "metadata": {
    "id": "ReO-ytcuyJL4",
    "outputId": "eb1b7f54-b4fa-4f75-bb49-8cb64cabab36"
   },
   "outputs": [],
   "source": [
    "%%writefile mm-openacc.c\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "void fill_matrix(double *A, int n)\n",
    "{\n",
    "  for(int i = 0; i < n; i++)\n",
    "    for(int j = 0; j < n; j++)\n",
    "      A[i*n+j] = rand()%(10-1)*1; \n",
    "}\n",
    "\n",
    "void print_matrix(double *A, int n)\n",
    "{\n",
    "  for(int i = 0; i < n; i++){\n",
    "    for(int j = 0; j < n; j++)\n",
    "      printf(\"%1.2f\\t\", A[i*n+j]);\n",
    "    printf(\"\\n\");\n",
    "  }\n",
    "\n",
    "  printf(\"\\n\");\n",
    "\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv)\n",
    "{\n",
    "  int n = atoi(argv[1]);  \n",
    "  int i, j, k;\n",
    "  struct timeval begin, end;\n",
    " \n",
    "  double *A = (double *) malloc (sizeof(double) * n * n);\n",
    "  double *B = (double *) malloc (sizeof(double) * n * n);\n",
    "  double *C = (double *) malloc (sizeof(double) * n * n);\n",
    "\n",
    "  fill_matrix(A,n);\n",
    "  fill_matrix(B,n);\n",
    " \n",
    "  gettimeofday(&begin, 0);\n",
    "      \n",
    "  #pragma acc data present_or_copyin(A[:n*n], B[:n*n], n) copyout(C[:n*n])\n",
    "   #pragma acc parallel \n",
    "    #pragma acc loop\n",
    "     for(i = 0; i < n; i++) \n",
    "       for(j = 0; j < n; j++)\n",
    "         for(k = 0; k < n; k++) \n",
    "           C[i*n+j] += A[i*n+k] * B[k*n+j];\n",
    "\n",
    "   gettimeofday(&end, 0); \n",
    "  \n",
    "   long seconds = end.tv_sec - begin.tv_sec;\n",
    "   long microseconds = end.tv_usec - begin.tv_usec;\n",
    "   double elapsed = seconds + microseconds*1e-6;\n",
    "    \n",
    "    printf(\"%d x %d  %.2f seconds\\n\", n, n, elapsed);  \n",
    "     \n",
    "  //print_matrix(A,n);\n",
    "  //print_matrix(B,n);\n",
    "  //print_matrix(C,n);\n",
    "\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Aif58O7xyJL4",
   "metadata": {
    "id": "Aif58O7xyJL4",
    "outputId": "42717882-1845-4955-f24b-ae1688da9cc5"
   },
   "outputs": [],
   "source": [
    "!pgcc mm-openacc.c -o mm-openacc -acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YNr5hHVYyJL5",
   "metadata": {
    "id": "YNr5hHVYyJL5",
    "outputId": "d311bd04-2828-4c37-ec76-643995de17ca"
   },
   "outputs": [],
   "source": [
    "!./mm-openacc 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nU4xEUl4yJL5",
   "metadata": {
    "id": "nU4xEUl4yJL5"
   },
   "source": [
    "### ⊗ OpenMP5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Z6xMCqBeyJL5",
   "metadata": {
    "id": "Z6xMCqBeyJL5",
    "outputId": "28667a6c-a198-4ac1-b396-9cfbc87702de"
   },
   "outputs": [],
   "source": [
    "%%writefile mm-omp5.c\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <omp.h>\n",
    "#include <sys/time.h>\n",
    "\n",
    "void fill_matrix(double *A, int n)\n",
    "{ \n",
    "  for(int i = 0; i < n; i++)\n",
    "    for(int j = 0; j < n; j++)\n",
    "      A[i*n+j] = rand()%(10-1)*1; \n",
    "}\n",
    "\n",
    "void print_matrix(double *A, int n)\n",
    "{\n",
    "  for(int i = 0; i < n; i++){\n",
    "    for(int j = 0; j < n; j++)\n",
    "      printf(\"%1.2f\\t\", A[i*n+j]);\n",
    "    printf(\"\\n\");\n",
    "  }\n",
    "  \n",
    "  printf(\"\\n\");\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv)\n",
    "{\n",
    "  int n = atoi(argv[1]);  \n",
    "  int i, j, k;\n",
    "  struct timeval begin, end;\n",
    "\n",
    "  double  *A = (double *) malloc (sizeof(double) * n * n);\n",
    "  double  *B = (double *) malloc (sizeof(double) * n * n);\n",
    "  double  *C = (double *) malloc (sizeof(double) * n * n);\n",
    "\n",
    "  fill_matrix(A,n);\n",
    "  fill_matrix(B,n);\n",
    "\n",
    "  gettimeofday(&begin, 0);\n",
    "    \n",
    "  #pragma omp target data map(to:A[:n*n], B[:n*n], n) map(from:C[:n*n])\n",
    "  {\n",
    "   #pragma omp target teams distribute parallel for private(i,j,k)\n",
    "   for(i = 0; i < n; i++) \n",
    "     for(j = 0; j < n; j++)\n",
    "       for(k = 0; k < n; k++) \n",
    "         C[i*n+j] += A[i*n+k] * B[k*n+j];\n",
    "  }\n",
    "\n",
    "   gettimeofday(&end, 0); \n",
    "    \n",
    "   long seconds = end.tv_sec - begin.tv_sec;\n",
    "   long microseconds = end.tv_usec - begin.tv_usec;\n",
    "   double elapsed = seconds + microseconds*1e-6;\n",
    "    \n",
    "    printf(\"%d x %d  %.2f seconds\\n\", n, n, elapsed);   \n",
    "  \n",
    "  //print_matrix(A,n);\n",
    "  //print_matrix(B,n);\n",
    "  //print_matrix(C,n);\n",
    "\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CmLRUJvIyJL5",
   "metadata": {
    "id": "CmLRUJvIyJL5"
   },
   "outputs": [],
   "source": [
    "!clang mm-omp5.c -o mm-omp5 -fopenmp -fopenmp-targets=nvptx64-nvidia-cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bsaExBeTyJL6",
   "metadata": {
    "id": "bsaExBeTyJL6",
    "outputId": "901bf666-b753-49b7-a3a4-b1de58755b59"
   },
   "outputs": [],
   "source": [
    "!./mm-omp5 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4241eb5c-b38b-4357-81a3-3efa506b59c0",
   "metadata": {},
   "source": [
    "### Comparison Performance Analysis using 1-GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-s2IqLFfyJL6",
   "metadata": {
    "id": "-s2IqLFfyJL6"
   },
   "source": [
    "| Program Version      | Execution Time (sec.)  | Speedup      |\n",
    "| :---                 |    :----:              |        ---:  |\n",
    "| Serial               | 4.55                   | 1X           |\n",
    "| OpenMP T=36          | 0.05                   | 91X          |\n",
    "| OpenACC              | 0.64                   | 7X           | \n",
    "| CUDA                 | 0.19                   | 24X          | \n",
    "| OpenMP5              | 2.11                   | 2X           | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3fc4d4-6627-49da-ac8b-b11462eeca0b",
   "metadata": {},
   "source": [
    "### ⊗ `CUDA Multi-GPU`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1552a9-c411-4953-97d2-f170fd2267e6",
   "metadata": {},
   "source": [
    "### Strategy: Static and Syncronous Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa592231-e2c2-4c94-b446-b5b88aeef072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mm-multi-GPU-sync.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile mm-multi-GPU-sync.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda.h>\n",
    "\n",
    "// CUDA kernel to perform matrix multiplication\n",
    "__global__ void matrixMultiply(float *A, float *B, float *C, int n) {\n",
    "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  int j = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "\n",
    "  if(i < n && j < n)\n",
    "    for( int k = 0; k < n; k++) \n",
    "       C[i*n+j] += A[i*n+k] * B[k*n+j];\n",
    "\n",
    "}\n",
    "\n",
    "// Function to perform matrix multiplication synchronously on multiple GPUs\n",
    "void matrixMultiplySync(float *a, float *b, float *c, int n, int num_gpus) {\n",
    "    \n",
    "    float *d_a[num_gpus], *d_b[num_gpus], *d_c[num_gpus];\n",
    "\n",
    "    int block_size = 2;\n",
    "    dim3 threadsPerBlock(block_size, block_size);\n",
    "    dim3 numBlocks((n + block_size - 1) / block_size, (n + block_size - 1) / block_size);\n",
    "\n",
    "    for (int i = 0; i < num_gpus; ++i) {\n",
    "        cudaSetDevice(i);\n",
    "        cudaMalloc(&d_a[i], n * n * sizeof(float));\n",
    "        cudaMalloc(&d_b[i], n * n * sizeof(float));\n",
    "        cudaMalloc(&d_c[i], n * n * sizeof(float));\n",
    "        cudaMemcpy(d_a[i], a, n * n * sizeof(float), cudaMemcpyHostToDevice);\n",
    "        cudaMemcpy(d_b[i], b, n * n * sizeof(float), cudaMemcpyHostToDevice);\n",
    "        \n",
    "                 matrixMultiply<<<numBlocks, threadsPerBlock>>>(d_a[i], d_b[i], d_c[i], n);\n",
    "        \n",
    "        cudaMemcpy(c, d_c[i], n * n * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    }\n",
    "\n",
    "    for (int i = 0; i < num_gpus; ++i) {\n",
    "        cudaSetDevice(i);\n",
    "        cudaFree(d_a[i]);\n",
    "        cudaFree(d_b[i]);\n",
    "        cudaFree(d_c[i]);\n",
    "    }\n",
    "}\n",
    "\n",
    "void printMatrix(float *A, int n)\n",
    "{\n",
    "  for(int i = 0; i < n; i++){\n",
    "    for(int j = 0; j < n; j++)\n",
    "      printf(\"%1.2f\\t\", A[i*n+j]);\n",
    "    printf(\"\\n\");\n",
    "  }\n",
    "\n",
    "  printf(\"\\n\");\n",
    "\n",
    "}\n",
    "\n",
    "void fillMatrix(float *A, int n)\n",
    "{ \n",
    "   for(int i=0; i < n; i++)\n",
    "     for(int j=0; j < n; j++)\n",
    "       A[i*n+j] = 1;//rand()%(10-1)*1;\n",
    "   \n",
    "}\n",
    "\n",
    "int main(int argc, char **argv) {\n",
    "\n",
    "    int n = atoi(argv[1]);         // Matrix size\n",
    "    int num_gpus = atoi(argv[2]);  // Number of GPUs\n",
    "\n",
    "    float *a = (float*)malloc(n * n * sizeof(float));\n",
    "    float *b = (float*)malloc(n * n * sizeof(float));\n",
    "    float *c = (float*)malloc(n * n * sizeof(float));\n",
    "\n",
    "    // Initialize matrices 'a' and 'b' here\n",
    "    fillMatrix(a, n);\n",
    "    fillMatrix(b, n);\n",
    "    \n",
    "    // Call matrix multiplication a/synchronously on multiple GPUs\n",
    "    matrixMultiplySync(a, b, c, n, num_gpus);\n",
    "    \n",
    "    // Print or use the result matrix 'c' as needed\n",
    "    printMatrix(a, n);\n",
    "    printMatrix(b, n);\n",
    "    printMatrix(c, n);\n",
    "\n",
    "    free(a);\n",
    "    free(b);\n",
    "    free(c);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfe62f5-6f28-45be-b367-62bca8f08d04",
   "metadata": {},
   "outputs": [],
   "source": [
    " !nvcc mm-multi-GPU-sync.cu -o mm-multi-GPU-sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045e25a5-01fa-4bcc-a94f-1904c7671964",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./mm-multi-GPU-sync 16 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87561f17-08cf-4c73-83a8-e8652f3aa944",
   "metadata": {},
   "source": [
    "### Strategy: Static and asynchronous Partition using OpenMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26894580-9f6d-4749-a68f-408e4458b7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mm-multi-GPU-async.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda.h>\n",
    "#include <omp.h>\n",
    "\n",
    "// CUDA kernel to perform matrix multiplication\n",
    "__global__ void matrixMultiply(float *A, float *B, float *C, int n) {\n",
    "  \n",
    "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  int j = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "\n",
    "  if(i < n && j < n)\n",
    "    for( int k = 0; k < n; k++) \n",
    "       C[i*n+j] += A[i*n+k] * B[k*n+j];\n",
    "}\n",
    "\n",
    "void matrixMultiplyAsync(float *a, float *b, float *c, int n, int num_gpus) {\n",
    " \n",
    "    #pragma omp parallel num_threads(num_gpus)\n",
    "    {\n",
    "        int gpu_id = omp_get_thread_num();\n",
    "        cudaSetDevice(gpu_id);\n",
    "\n",
    "        float *d_a, *d_b, *d_c;\n",
    "        cudaMalloc(&d_a, n * n * sizeof(float));\n",
    "        cudaMalloc(&d_b, n * n * sizeof(float));\n",
    "        cudaMalloc(&d_c, n * n * sizeof(float));\n",
    "\n",
    "        cudaMemcpyAsync(d_a, a, n * n * sizeof(float), cudaMemcpyHostToDevice);\n",
    "        cudaMemcpyAsync(d_b, b, n * n * sizeof(float), cudaMemcpyHostToDevice);\n",
    "\n",
    "        //dim3 threadsPerBlock(2, 2);\n",
    "        //dim3 numBlocks((n + 15) / 16, (n + 15) / 16);\n",
    "        int block_size = 2;\n",
    "        dim3 threadsPerBlock(block_size, block_size);\n",
    "        dim3 numBlocks((n + block_size - 1) / block_size, (n + block_size - 1) / block_size);\n",
    "\n",
    "        matrixMultiply<<<numBlocks, threadsPerBlock>>>(d_a, d_b, d_c, n);\n",
    "\n",
    "        cudaMemcpyAsync(c, d_c, n * n * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "\n",
    "        cudaFree(d_a);\n",
    "        cudaFree(d_b);\n",
    "        cudaFree(d_c);\n",
    "    }\n",
    "}\n",
    "\n",
    "void printMatrix(float *A, int n)\n",
    "{\n",
    "  for(int i = 0; i < n; i++){\n",
    "    for(int j = 0; j < n; j++)\n",
    "      printf(\"%1.2f\\t\", A[i*n+j]);\n",
    "    printf(\"\\n\");\n",
    "  }\n",
    "\n",
    "  printf(\"\\n\");\n",
    "\n",
    "}\n",
    "\n",
    "void fillMatrix(float *A, int n)\n",
    "{ \n",
    "   for(int i=0; i < n; i++)\n",
    "     for(int j=0; j < n; j++)\n",
    "       A[i*n+j] = 1;//rand()%(10-1)*1;  \n",
    "}\n",
    "\n",
    "\n",
    "int main(int argc, char **argv) {\n",
    "\n",
    "    int n = atoi(argv[1]);         // Matrix size\n",
    "    int num_gpus = atoi(argv[2]);  // Number of GPUs\n",
    "\n",
    "    float *a = (float*)malloc(n * n * sizeof(float));\n",
    "    float *b = (float*)malloc(n * n * sizeof(float));\n",
    "    float *c = (float*)malloc(n * n * sizeof(float));\n",
    "\n",
    "    // Initialize matrices 'a' and 'b' here\n",
    "    fillMatrix(a, n);\n",
    "    fillMatrix(b, n);\n",
    "    \n",
    "    // Call matrix multiplication asynchronously on multiple GPUs \n",
    "    matrixMultiplyAsync(a, b, c, n, num_gpus);\n",
    "\n",
    "    // Print or use the result matrix 'c' as needed\n",
    "    printMatrix(a, n);\n",
    "    printMatrix(b, n);\n",
    "    printMatrix(c, n);\n",
    "\n",
    "    free(a);\n",
    "    free(b);\n",
    "    free(c);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65c721c-2e7a-4113-82aa-2d3d840b709d",
   "metadata": {},
   "outputs": [],
   "source": [
    " !nvcc mm-multi-GPU-async.cu -o mm-multi-GPU-async -Xcompiler -fopenmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa40dc75-748c-47ef-b7eb-d542eaeb6959",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./mm-multi-GPU-async 16 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bPQOHun4yJL6",
   "metadata": {
    "id": "bPQOHun4yJL6"
   },
   "source": [
    "## Next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-wJF9DQryJL7",
   "metadata": {
    "id": "-wJF9DQryJL7"
   },
   "source": [
    "Please continue to the next notebook: Please continue to the next notebook: [Accelerate a Thermal Conductivity Application](2-heat.ipynb)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "FUm5HQBwyJLm",
    "Jq8Zc_8byJLp",
    "bzhJyfWIyJLr",
    "bPQOHun4yJL6"
   ],
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "https://github.com/muriloboratto/SIINTEC2022/blob/master/1-SIINTEC2022-Introduction.ipynb",
     "timestamp": 1666528573400
    }
   ]
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
